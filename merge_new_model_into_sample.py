import multiprocessing
import os

import pandas as pd
from pandas import DataFrame

import global_values
from experiments.experimental_setting_1 import call_experimental_setting_1

from experiments.experimental_setting_2_5 import call_experimental_setting_2_and_5
from experiments.experimental_setting_3 import call_experimental_setting_3
from experiments.experimental_setting_4 import call_experimental_setting_4

model_to_merge = 'Qwen/Qwen2.5-32B-Instruct'


def perform_result_merge(experiment_num, result_file_name, indices_to_remove: DataFrame, dataset, model, result_column=None):
    if not os.path.exists(f'data/outputs/{dataset}/merge/{model_to_merge}/{model}'):
        os.makedirs(f'data/outputs/{dataset}/merge/{model_to_merge}/{model}')

    # Merge experiment
    if os.path.exists(
            f'data/outputs/{dataset}/merge/{model_to_merge}/{model}/{result_file_name}.csv'):
        # print(f'Skipping Merge of Experiment {experiment_num} for {dataset}/{model} as it is already complete')
        return

    # Load original, insert
    if not os.path.exists(f'data/outputs/{dataset}/{model}/{result_file_name}.csv'):
        print(
            f'WARNING: Cannot Merge Experiment {experiment_num} for {dataset}/{model} as an original result does not exist to merge!')
        return
    if not os.path.exists(f'data/outputs/{dataset}/diffs/{model_to_merge}/{model}/{result_file_name}.csv'):
        print(
            f'WARNING: Cannot Merge Experiment {experiment_num} for {dataset}/{model} as a diff result does not exist to merge!')
        return
    df_orig = pd.read_csv(f'data/outputs/{dataset}/{model}/{result_file_name}.csv', index_col='question_idx')
    df_insert = pd.read_csv(f'data/outputs/{dataset}/diffs/{model_to_merge}/{model}/{result_file_name}.csv',
                            index_col='question_idx')
    if result_column is not None:
        if (df_orig[result_column].isna() | df_orig[result_column].astype(str).str.strip().eq('')) .any():
            print(
                f'WARNING: Cannot Merge Experiment {experiment_num} for {dataset}/{model} as original norm is not complete/reviewed by human!')
            return

        if (df_insert[result_column].isna() | df_insert[result_column].astype(str).str.strip().eq('')).any():
            print(
                f'WARNING: Cannot Merge Experiment {experiment_num} for {dataset}/{model} as diff norm is not complete/reviewed by human!')
            return

    # Concat original with removed diff with the insert diff and output
    df_out = pd.concat([df_orig.loc[~df_orig.index.isin(indices_to_remove.index)], df_insert])
    if df_out.index.drop_duplicates().shape[0] != 100:
        print(f'ERROR: merge record size incorrect. Aborting')
        return
    df_out.to_csv(f'data/outputs/{dataset}/merge/{model_to_merge}/{model}/{result_file_name}.csv')



if __name__ == '__main__':
    for dataset_name in global_values.datasets:
        if os.path.exists(f'data/outputs/{dataset_name}/diffs/{model_to_merge}'):
            print(f'Skipping generation of diff dataset for {model_to_merge} on {dataset_name} as it already exists')
            continue
        # First figure out the new common correctly answered questions for this dataset
        common_correct: DataFrame = None
        for model_name in global_values.models:
            df: DataFrame = pd.read_csv(
                f'data/outputs/{dataset_name}/{model_name}/step_0_raw_mcqa_performance_normed.csv',
                index_col='question_idx')
            # df = df.drop(df.columns[0], axis=1)  # Drop the unnamed autogenerated column from the step 0 runs
            df = df[df['base_answer_correct'] == True]
            if common_correct is None:
                common_correct = df
            else:
                common_correct = df.loc[
                    df.index.isin(common_correct.index)]  # Equivalent of an inner exist join on question_idx
        common_correct = common_correct.drop_duplicates()

        # Next diff against the 100 sample to determine which old indexes need to be dropped.
        existing_sample = pd.read_csv(f'data/outputs/{dataset_name}/step_1_mcqa_all_models_correct_sample.csv',
                                      index_col='question_idx')
        to_remove: DataFrame = existing_sample[~existing_sample.index.isin(common_correct.index)]
        to_keep: DataFrame = existing_sample[existing_sample.index.isin(common_correct.index)]
        num_to_replace = to_remove.shape[0]
        print(
            f'{dataset_name}: Removing {num_to_replace} items from existing sample due to merged model answering question incorrect')

        # Next diff common_correct against existing_sample to retrieve set of sampleable records
        new_sampled_records = common_correct[~common_correct.index.isin(existing_sample.index)].sample(num_to_replace)
        print(f'{dataset_name}: Sampling {num_to_replace} items')

        # Now write diff
        output_dir = f'data/outputs/{dataset_name}/diffs/{model_to_merge}'
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        new_sampled_records.to_csv(
            f'data/outputs/{dataset_name}/diffs/{model_to_merge}/step_1_mcqa_all_models_correct_sample.csv')
        to_remove.to_csv(
            f'data/outputs/{dataset_name}/diffs/{model_to_merge}/step_1_mcqa_all_models_correct_sample_removed.csv')

        # Rewrite new sample
        to_write = pd.concat([to_keep, new_sampled_records])
        to_write.to_csv(f'data/outputs/{dataset_name}/step_1_mcqa_all_models_correct_sample.csv')

    # Now run experiments in prep for merge
    for dataset_name in global_values.datasets:
        for model_name in global_values.models:
            work_dir = f'diffs/{model_to_merge}'
            if model_name == model_to_merge:
                work_dir = ''
            # -- Settings 1 and 4
            if not os.path.exists(
                    f'data/outputs/{dataset_name}/{work_dir}/{model_name}/step_6_self_consistency_permuted_new.csv'):
                print(f'Generating Merge for {dataset_name}/{work_dir}/{model_name} Experimental Setting 1')
                process = multiprocessing.Process(target=call_experimental_setting_1,
                                                  args=(model_name, dataset_name, work_dir),
                                                  name="exp_setting_1")
                process.start()
                process.join()
            else:
                print(f'Skipping experimental setting 1 for {dataset_name}/{work_dir}/{model_name}: Already Exists')
                if not os.path.exists(
                        f'data/outputs/{dataset_name}/{model_name}/step_6_self_consistency_permuted_new_normed.csv'):
                    print(
                        f'Warning: Norm for experimental setting 1 {dataset_name}/{work_dir}/{model_name} Does not yet Exist')

            if not os.path.exists(f'data/outputs/{dataset_name}/{work_dir}/{model_name}/step_7_self_consistency_permuted_no_context.csv'):
                print(f'Generating Merge for {dataset_name}/{work_dir}/{model_name} Experimental Setting 4')
                process = multiprocessing.Process(target=call_experimental_setting_4,
                                                  args=(model_name, dataset_name, work_dir),
                                                  name="exp_setting_1")
                process.start()
                process.join()
            else:
                print(f'Skipping experimental setting 4 for {dataset_name}/{work_dir}/{model_name}: Already Exists')
                if not os.path.exists(
                        f'data/outputs/{dataset_name}/{work_dir}/{model_name}/step_7_self_consistency_permuted_no_context_normed.csv'):
                    print(f'Warning: Norm for experimental setting 4 {dataset_name}/{work_dir}/{model_name} Does not yet Exist')

            # -- Settings 2 and 5
            if not os.path.exists(f'data/outputs/{dataset_name}/{work_dir}/{model_name}/step_5_no_correct_answer.csv'):
                print(f'Generating Merge for {dataset_name}/{work_dir}/{model_name} Experimental Settings 2 & 5')

                process = multiprocessing.Process(target=call_experimental_setting_2_and_5,
                                                  args=(model_name, dataset_name, work_dir),
                                                  name="exp_setting_2_5")
                process.start()
                process.join()
            else:
                print(f'Skipping experimental setting 2/5 for {dataset_name}/{work_dir}/{model_name}: Already Exists')
                if not os.path.exists(
                        f'data/outputs/{dataset_name}/{model_name}/step_5_no_correct_answer_normed.csv'):
                    print(
                        f'Warning: Norm for experimental setting 2/5 {dataset_name}/{work_dir}/{model_name} Does not yet Exist')

            # -- Setting 3
            if not os.path.exists(f'data/outputs/{dataset_name}/{work_dir}/{model_name}/step_8_long_context.csv'):
                print(f'Generating Merge for {dataset_name}/{work_dir}/{model_name} Experimental Setting 3')
                process = multiprocessing.Process(target=call_experimental_setting_3,
                                                  args=(model_name, dataset_name, work_dir),
                                                  name="exp_setting_3")
                process.start()
                process.join()
            else:
                print(f'Skipping experimental setting 3 for {dataset_name}/{work_dir}/{model_name}: Already Exists')
                if not os.path.exists(
                        f'data/outputs/{dataset_name}/{work_dir}/{model_name}/step_8_long_context_normed.csv'):
                    print(
                        f'Warning: Norm for experimental setting 3 {dataset_name}/{work_dir}/{model_name} Does not yet Exist')

    # Now Merge
    for dataset_name in global_values.datasets:
        if not os.path.exists(
                f'data/outputs/{dataset_name}/diffs/{model_to_merge}/step_1_mcqa_all_models_correct_sample_removed.csv'):
            print(
                f'Skipping Merge for {dataset_name} as a diff result for removal does not exist to merge!')
            continue
        to_remove = pd.read_csv(
            f'data/outputs/{dataset_name}/diffs/{model_to_merge}/step_1_mcqa_all_models_correct_sample_removed.csv',
            index_col='question_idx')
        for model_name in global_values.models:
            if model_name == model_to_merge:
                continue
            perform_result_merge('Setting 1 Raw', 'step_6_self_consistency_permuted_new', to_remove, dataset_name,
                                 model_name)
            perform_result_merge('Setting 1 Norm', 'step_6_self_consistency_permuted_new_normed', to_remove,
                                 dataset_name,
                                 model_name,
                                 'permuted_answer_correct')
            perform_result_merge('Setting 2/5 Raw', 'step_5_no_correct_answer', to_remove, dataset_name,
                                 model_name)
            perform_result_merge('Setting 2/5 Normed', 'step_5_no_correct_answer_normed', to_remove, dataset_name,
                                 model_name, 'no_valid_option_explicit_answer_correct')
            perform_result_merge('Setting 3 Raw', 'step_8_long_context', to_remove, dataset_name,
                                 model_name)
            perform_result_merge('Setting 3 Normed', 'step_8_long_context_normed', to_remove, dataset_name,
                                 model_name, 'expanded_context_answer_correct')
            perform_result_merge('Setting 4 Raw', 'step_7_self_consistency_permuted_no_context', to_remove,
                                 dataset_name,
                                 model_name)
            perform_result_merge('Setting 4 Normed', 'step_7_self_consistency_permuted_no_context_normed', to_remove,
                                 dataset_name,
                                 model_name, 'permuted_answer_correct')
            perform_result_merge('Setting 6 Raw', 'step_9_shuffled_context', to_remove, dataset_name,
                                 model_name)
            perform_result_merge('Setting 6 Normed', 'step_9_shuffled_context_normed', to_remove, dataset_name,
                                 model_name, 'shuffled_context_answer_correct')